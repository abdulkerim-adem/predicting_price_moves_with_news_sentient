{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Imports",
   "id": "630e16d04d040af1"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import pandas as pd\n",
    "from typing import List, Dict"
   ],
   "id": "bcecf0e051ef9dae"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Class Declaration",
   "id": "8f2cda3d4acb56da"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class SentimentAggregator:\n",
    "    def __init__(self, articles: List):\n",
    "        self.articles = articles  # list of NewsArticle or dict-likes with .headline/.stock/.date\n",
    "\n",
    "    def aggregate_daily(self) -> pd.DataFrame:\n",
    "        records = []\n",
    "        for art in self.articles:\n",
    "            # assume art has .sentiment_score computed already; if not, call compute_sentiment()\n",
    "            if getattr(art, 'sentiment_score', None) is None and hasattr(art, 'compute_sentiment'):\n",
    "                art.compute_sentiment()\n",
    "            records.append({\n",
    "                'date': art.date,\n",
    "                'stock': art.stock,\n",
    "                'sentiment': art.sentiment_score\n",
    "            })\n",
    "        df = pd.DataFrame(records)\n",
    "        grouped = df.groupby(['stock', 'date'])['sentiment'].mean().reset_index()\n",
    "        return grouped  # columns: stock, date, sentiment\n",
    "\n",
    "\n",
    "class CorrelationAnalyzer:\n",
    "    def __init__(self, sentiment_df: pd.DataFrame, stock_quant_map: Dict[str, object], lag: int = 0):\n",
    "        \"\"\"\n",
    "        sentiment_df: columns ['stock','date','sentiment']\n",
    "        stock_quant_map: e.g. {'AAPL': QuantitativeAnalysis instance, ...}\n",
    "        lag: integer number of days to shift sentiment forward (e.g., 1 means sentiment on T used to predict return on T+1)\n",
    "        \"\"\"\n",
    "        self.sentiment_df = sentiment_df.copy()\n",
    "        self.stock_quant_map = stock_quant_map\n",
    "        self.lag = lag\n",
    "\n",
    "    def prepare_merged(self, stock: str) -> pd.DataFrame:\n",
    "        sent = self.sentiment_df[self.sentiment_df['stock'] == stock].copy()\n",
    "        sent = sent.rename(columns={'date': 'Date'}).sort_values('Date')\n",
    "        if self.lag != 0:\n",
    "            sent['Date'] = sent['Date'] + pd.Timedelta(days=self.lag)\n",
    "        quant = self.stock_quant_map[stock].df.copy()\n",
    "        merged = pd.merge(quant, sent[['Date', 'sentiment']], on='Date', how='inner')\n",
    "        return merged  # has price, indicators, daily_return, sentiment\n",
    "\n",
    "    def compute_correlations(self) -> pd.DataFrame:\n",
    "        rows = []\n",
    "        for stock in self.sentiment_df['stock'].unique():\n",
    "            if stock not in self.stock_quant_map:\n",
    "                continue\n",
    "            merged = self.prepare_merged(stock)\n",
    "            if merged.empty:\n",
    "                continue\n",
    "            base = merged[['sentiment', 'daily_return']].dropna()\n",
    "            pearson_ret = base['sentiment'].corr(base['daily_return'])\n",
    "            # optional: Spearman\n",
    "            spearman_ret = base['sentiment'].rank().corr(base['daily_return'].rank())\n",
    "            rows.append({\n",
    "                'stock': stock,\n",
    "                'feature': 'daily_return',\n",
    "                'pearson': pearson_ret,\n",
    "                'spearman': spearman_ret,\n",
    "                'n': len(base)\n",
    "            })\n",
    "            # indicator correlations, e.g., RSI, MACD_hist if present\n",
    "            for ind in ['RSI', 'MACD_hist']:\n",
    "                if ind in merged:\n",
    "                    tmp = merged[['sentiment', ind]].dropna()\n",
    "                    if tmp.empty:\n",
    "                        continue\n",
    "                    pearson_ind = tmp['sentiment'].corr(tmp[ind])\n",
    "                    spearman_ind = tmp['sentiment'].rank().corr(tmp[ind].rank())\n",
    "                    rows.append({\n",
    "                        'stock': stock,\n",
    "                        'feature': ind,\n",
    "                        'pearson': pearson_ind,\n",
    "                        'spearman': spearman_ind,\n",
    "                        'n': len(tmp)\n",
    "                    })\n",
    "        return pd.DataFrame(rows)\n",
    "\n",
    "    def simple_signal_evaluation(self, stock: str):\n",
    "        merged = self.prepare_merged(stock)\n",
    "        if merged.empty:\n",
    "            return None\n",
    "        # Example signal: positive if sentiment>0 and RSI<70; negative if sentiment<0 and RSI>30\n",
    "        signal = []\n",
    "        for _, row in merged.iterrows():\n",
    "            if row.get('sentiment', 0) > 0 and row.get('RSI', 100) < 70:\n",
    "                signal.append(1)\n",
    "            elif row.get('sentiment', 0) < 0 and row.get('RSI', 0) > 30:\n",
    "                signal.append(-1)\n",
    "            else:\n",
    "                signal.append(0)\n",
    "        merged['signal'] = signal\n",
    "        # Shift return to next day to simulate prediction (optional)\n",
    "        merged['next_return'] = merged['daily_return'].shift(-1)\n",
    "        eval_df = merged.dropna(subset=['next_return'])\n",
    "        summary = eval_df.groupby('signal')['next_return'].agg(['mean', 'count'])\n",
    "        return summary\n"
   ]
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## News Article",
   "id": "d5d2c5167115b0f9"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "# news.py equivalent\n",
    "from textblob import TextBlob\n",
    "import pandas as pd\n",
    "\n",
    "class NewsArticle:\n",
    "    def __init__(self, headline: str, url: str, publisher: str, date: str, stock: str):\n",
    "        self.headline = headline\n",
    "        self.url = url\n",
    "        self.publisher = publisher\n",
    "        self.stock = stock\n",
    "        self.date = pd.to_datetime(date).normalize()\n",
    "        self.sentiment_score = None\n",
    "\n",
    "    def compute_sentiment(self):\n",
    "        self.sentiment_score = TextBlob(self.headline).sentiment.polarity\n",
    "        return self.sentiment_score\n"
   ],
   "id": "a53621753dc23f69"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "### articles and stock quant map",
   "id": "1205a7d0a8e24aad"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "from notebooks.quantitative_analysis import QuantitativeAnalysis\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# 1. Load news and create NewsArticle list\n",
    "news_df = pd.read_csv(\"../data/raw_analyst_settings.csv\")  # or your actual filename\n",
    "news_df['date'] = pd.to_datetime(news_df['date'], errors='coerce').dt.normalize()\n",
    "\n",
    "articles = []\n",
    "for _, row in news_df.dropna(subset=['date']).iterrows():\n",
    "    art = NewsArticle(\n",
    "        headline=row['headline'],\n",
    "        url=row.get('url', \"\"),\n",
    "        publisher=row.get('publisher', \"\"),\n",
    "        date=row['date'],\n",
    "        stock=row['stock']\n",
    "    )\n",
    "    art.compute_sentiment()\n",
    "    articles.append(art)\n",
    "\n",
    "# 2. Load each stock and wrap with QuantitativeAnalysis\n",
    "tickers = [\"AAPL\", \"AMZN\", \"GOOG\", \"META\", \"MSFT\", \"NVDA\", \"TSLA\"]\n",
    "stock_quant_map = {}\n",
    "for t in tickers:\n",
    "    path = Path(f\"../data/{t}_historical_data.csv\")\n",
    "    if not path.exists():\n",
    "        continue\n",
    "    df = pd.read_csv(path)\n",
    "    qa = QuantitativeAnalysis(df)\n",
    "    qa.add_sma(20)\n",
    "    qa.add_sma(50)\n",
    "    qa.add_rsi()\n",
    "    stock_quant_map[t] = qa\n"
   ],
   "id": "b2d485f2851f0c2f"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Class usage",
   "id": "ebe1722ed3e7146b"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "sent_agg = SentimentAggregator(articles)\n",
    "sentiment_df = sent_agg.aggregate_daily()\n",
    "\n",
    "corr = CorrelationAnalyzer(sentiment_df, stock_quant_map, lag=1)\n",
    "corr_df = corr.compute_correlations()\n",
    "display(corr_df)\n",
    "\n",
    "eval_summary = corr.simple_signal_evaluation(\"AAPL\")\n",
    "print(eval_summary)\n"
   ],
   "id": "48ea90b6a2db9267"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
